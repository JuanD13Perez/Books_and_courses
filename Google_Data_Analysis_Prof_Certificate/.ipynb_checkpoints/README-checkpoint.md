# Google Data Analysis Professional Capstone Project
- [English Version](#English-Version) 
- [Spanish Version](#Spanish-Version)

## Spanish Version

### **Problema de negocio** 游닇
Este proyecto hace parte del certificado profesional de Google en an치lisis de datos.
Usamos el dataset de la marca _FitBit_, disponible v칤a [**Kaggle**](https://www.kaggle.com/datasets/arashnic/fitbit), que corresponden a registros de un dispositvo (Smartwatch) con informaci칩n de consumo de calor칤as, n칰mero de pasos, etc.
En este caso, asumimos que trabajamos para Bellabeat, una competidora de FitBit. Nuestra tarea consiste en **identificar patrones de consumo en los usuarios de los productos FitBit** que puedan apoyar la estrategia de Marketing de la compa침칤a.

| ![Banner](FitBit_Banner.png) |
|:--:|
| <b>Image Credits - Banner - https://www.kaggle.com/datasets/arashnic/fitbit  </b>|


### **Highlights** 
Este proyecto se hizo utlizando python 3.10.5 en un entorno de Jupyter Notebooks. Consta de tres secciones principales:
- [**Ap칠ndice**](#Ap칠ndice)
- [**Data Cleaning**](#Data-Cleaning)
- [**Data Analysis**](#Data-Analysis)
### Ap칠ndice
Aqu칤 manipulamos desde el sistema el [dataset](https://www.kaggle.com/datasets/arashnic/fitbit) con el fin de obtener todos los archivos csv como pandas dataframes. Nos dimos cuenta que la estructura de datos es similar a la de una base relacional y que ciertos dataframes son meramente agregaciones de los datos minuto a minuto. Decidimos trabajar 칰nicamente con 칠stos dataframes 'ra칤z'. 

Tenemos informaci칩n por minuto de:
* Calor칤as
* Intensidad de ejercicio
* METs
* N칰mero de pasos
* Ritmo card칤aco
Informaci칩n diaria de:
* Sue침o
* Peso

### Data Cleaning:

0. Restringimos a 19 usuarios de los 25 originalmente disponibles. Ya que 6 usuarios ten칤an la informaci칩n muy incompleta (no alcanzaban a cubrir un mes de datos).
1. Restringimos el rango de fechas desde 2016-04-12 hasta 2016-05-11 minuto a minuto. Esto para tener informaci칩n de tiempo comparable para los distintos usuarios. Aqu칤 se usaron todos los datos de Calor칤as, Intensidades, METs y Steps.
2. Interpolamos usando statistical matching registros faltantes de sue침o y a침adimos ruido normal para completar registros inexistentes de algunos usuarios a fin de evitar sesgo y respetar la distribuci칩n original. Datos son diarios para el mismo per칤odo. Ver nota.
3. Interpolamos datos faltantes de ritmo card칤aco usando f칩rmula que relaciona METs., bas치ndonos en un m칠todo lineal robusto expuesto en [ELSEVIER- Int J Cardiol Heart Vasc.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6003065/). Adem치s a침adimos registros inexistentes con la misma f칩rmula + resampleo aleatorio de los registros existentes para tener datos que respeten la distribuci칩n original de los Id's presentes. Ver nota.
4. Desestimamos el uso de los datos de Peso al ser la mayor칤a subjetivamente ingresados por los usuarios. Esto los hace vulnerables a sesgo o malas mediciones. Adem치s cont치bamos con muy pocos registros completos (apenas 2 de 19).

Nota: Obviamente entendemos que estos datos son ficticios. En un caso real el problema de la falta de registros deber칤a tratarse con los stakeholders. El 칰nico prop칩sito aqu칤 es demostrar habilidad en el uso de herramientas estad칤sticas. El muestreo aleatorio puede llevar a un conjunto de datos de mayor calidad, reduciendo el sesgo que 칰nicamente usando la peque침a proporci칩n incompleta de datos disponibles. Sin embargo, no defendemos aqu칤 que sea una buena pr치ctica hacer este tipo de interpolaciones.

### Data Analysis: 
Intentamos identificar patrones en el uso del dispositivo en 3 frentes:
* A) Ejercicio
* B) Sue침o
* C) 



#### Conclusiones


### Requerimientos
 * Descargar el dataset desde [Kaggle Fit Bit](https://www.kaggle.com/datasets/arashnic/fitbit)
 * Se us칩 Python 3.10.5 y las siguientes librer칤as:
 ```
pandas
numpy 
from scipy.stats import trim_mean
matplotlib.pyplot
seaborn
 ````

## English Version